#!/usr/bin/env python

import datetime
import httplib
import httplib2
import logging
import json
import optparse
import subprocess
import uuid

from yar.util import clparserutil
import yar.util.basic


def create_database(key_store_host):

    database = "das"+str(uuid.uuid4()).replace("-", "")

    exit_code = subprocess.call([
        "key_store_installer",
        "--host=%s" % key_store_host,
        "--database=%s" % database,
        "--create=True",
        "--delete=False",
    ])
    if 0 != exit_code:
        return None

    return "%s/%s" % (key_store_host, database)


def delete_database(database):
    http_client = httplib2.Http()
    response, content = http_client.request(
        "http://%s" % database,
        "DELETE")
    return httplib.OK == response.status


def create_basic_creds(principal):
    api_key = yar.util.basic.APIKey.generate()
    rv = {
        "_id": api_key,
        "principal": principal,
        "type": "creds_v1.0",
        "is_deleted": False,
        "basic": {
            "api_key": api_key,
        },
    }
    return rv


def create_lots_of_creds_and_bulk_save_to_database(database, principal, number_of_creds):

    http_client = httplib2.Http()

    #
    # using CouchDB's bulk insertion api provides signifiant performance
    # improvements over inserting credentials one by one. docs for the API
    # can be found at:
    #
    #   http://couchdb.readthedocs.org/en/latest/api/database/bulk-api.html?highlight=_bulk_docs#db-bulk-docs
    #
    start_create_creds_timestamp = datetime.datetime.now()
    body = {
        "docs": [create_basic_creds(principal) for i in range(0, number_of_creds)],
    }
    end_create_creds_timestamp = datetime.datetime.now()

    start_persist_creds_timestamp = datetime.datetime.now()
    body_as_json = json.dumps(body)
    headers = {
        "Content-type": "application/json; charset=utf8",
        "Content-length": str(len(body_as_json)),
    }
    response, content = http_client.request(
        "http://%s/_bulk_docs" % database,
        "POST",
        body=body_as_json,
        headers=headers)
    if httplib.CREATED != response.status:
        pass
    end_persist_creds_timestamp = datetime.datetime.now()

    #
    # now the creds have been saved, let's query the database to
    # get a sense of its size. API docs for this database request
    # can be found at:
    #
    #   http://couchdb.readthedocs.org/en/latest/api/database/common.html#get--db
    #
    body_as_json = json.dumps(body)
    headers = {
        "Content-type": "application/json; charset=utf8",
        "Content-length": str(len(body_as_json)),
    }
    response, content = http_client.request(
        "http://%s" % database,
        "GET")
    if httplib.OK != response.status:
        pass

    content = json.loads(content)
    return (
        content["doc_count"],
        content["data_size"],
        content["disk_size"],
        (end_create_creds_timestamp - start_create_creds_timestamp).seconds,
        (end_persist_creds_timestamp - start_persist_creds_timestamp).seconds
    )


def bytes_to_megabytes(bytes):
    """Convert an integer value representing a number of bytes into another
    integer value representing the equivalent number of megabytes."""
    return int(bytes / (1024.0 * 1024.0))


class CommandLineParser(optparse.OptionParser):

    def __init__(self):

        description = (
            "The Key Store Credentials Generator is a load testing "
            "analyze the Key Store's characteristics when the Key "
            "Store contains lots of credentials."
        )
        optparse.OptionParser.__init__(
            self,
            "usage: %prog [options]",
            description=description,
            option_class=clparserutil.Option)

        default = "127.0.0.1:5984"
        help = "where's CouchDB running - default = %s" % default
        self.add_option(
            "--ksh",
            action="store",
            dest="key_store_host",
            default=default,
            type="hostcolonport",
            help=help)


if __name__ == "__main__":
    clp = CommandLineParser()
    (clo, cla) = clp.parse_args()

    database = create_database(clo.key_store_host)

    principal = "dave@example.com"

    number_of_creds_to_add = [
        1000,
        24000,
    ]
    # number_of_creds_to_add.extend([25000] * 39)

    header = (
        "Number of Credentials\t"
        "Data Size (MB)\t"
        "Disk Size (MB)\t"
        "Time to Create Creds (seconds)\t"
        "Time to Persist Creds (seconds)"
    )
    print header

    for number_of_creds in number_of_creds_to_add:
        (number_creds, data_size, disk_size, seconds_to_create_creds, seconds_to_persist_creds) = \
            create_lots_of_creds_and_bulk_save_to_database(
                database,
                principal,
                number_of_creds)
        print "%s\t%s\t%s\t%s\t%s" % (
            number_creds,
            bytes_to_megabytes(data_size),
            bytes_to_megabytes(disk_size),
            seconds_to_create_creds,
            seconds_to_persist_creds)

    delete_database(database)
